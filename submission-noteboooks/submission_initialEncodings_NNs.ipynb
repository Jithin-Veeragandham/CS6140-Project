{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from xgboost import XGBClassifier\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtypes = {\n",
    "        'MachineIdentifier':                                    'category',\n",
    "        'ProductName':                                          'category',\n",
    "        'EngineVersion':                                        'category',\n",
    "        'AppVersion':                                           'category',\n",
    "        'AvSigVersion':                                         'category',\n",
    "        'IsBeta':                                               'int8',\n",
    "        'RtpStateBitfield':                                     'float32',\n",
    "        'IsSxsPassiveMode':                                     'int8',\n",
    "        'DefaultBrowsersIdentifier':                            'float32',\n",
    "        'AVProductStatesIdentifier':                            'float32',\n",
    "        'AVProductsInstalled':                                  'float32',\n",
    "        'AVProductsEnabled':                                    'float32',\n",
    "        'HasTpm':                                               'int8',\n",
    "        'CountryIdentifier':                                    'int16',\n",
    "        'CityIdentifier':                                       'float32',\n",
    "        'OrganizationIdentifier':                               'float32',\n",
    "        'GeoNameIdentifier':                                    'float32',\n",
    "        'LocaleEnglishNameIdentifier':                          'int8',\n",
    "        'Platform':                                             'category',\n",
    "        'Processor':                                            'category',\n",
    "        'OsVer':                                                'category',\n",
    "        'OsBuild':                                              'int16',\n",
    "        'OsSuite':                                              'int16',\n",
    "        'OsPlatformSubRelease':                                 'category',\n",
    "        'OsBuildLab':                                           'category',\n",
    "        'SkuEdition':                                           'category',\n",
    "        'IsProtected':                                          'float32',\n",
    "        'AutoSampleOptIn':                                      'int8',\n",
    "        'PuaMode':                                              'category',\n",
    "        'SMode':                                                'float32',\n",
    "        'IeVerIdentifier':                                      'float32',\n",
    "        'SmartScreen':                                          'category',\n",
    "        'Firewall':                                             'float32',\n",
    "        'UacLuaenable':                                         'float32',\n",
    "        'Census_MDC2FormFactor':                                'category',\n",
    "        'Census_DeviceFamily':                                  'category',\n",
    "        'Census_OEMNameIdentifier':                             'float32',\n",
    "        'Census_OEMModelIdentifier':                            'float32',\n",
    "        'Census_ProcessorCoreCount':                            'float32',\n",
    "        'Census_ProcessorManufacturerIdentifier':               'float32',\n",
    "        'Census_ProcessorModelIdentifier':                      'float32',\n",
    "        'Census_ProcessorClass':                                'category',\n",
    "        'Census_PrimaryDiskTotalCapacity':                      'float32',\n",
    "        'Census_PrimaryDiskTypeName':                           'category',\n",
    "        'Census_SystemVolumeTotalCapacity':                     'float32',\n",
    "        'Census_HasOpticalDiskDrive':                           'int8',\n",
    "        'Census_TotalPhysicalRAM':                              'float32',\n",
    "        'Census_ChassisTypeName':                               'category',\n",
    "        'Census_InternalPrimaryDiagonalDisplaySizeInInches':    'float32',\n",
    "        'Census_InternalPrimaryDisplayResolutionHorizontal':    'float32',\n",
    "        'Census_InternalPrimaryDisplayResolutionVertical':      'float32',\n",
    "        'Census_PowerPlatformRoleName':                         'category',\n",
    "        'Census_InternalBatteryType':                           'category',\n",
    "        'Census_InternalBatteryNumberOfCharges':                'float32',\n",
    "        'Census_OSVersion':                                     'category',\n",
    "        'Census_OSArchitecture':                                'category',\n",
    "        'Census_OSBranch':                                      'category',\n",
    "        'Census_OSBuildNumber':                                 'int16',\n",
    "        'Census_OSBuildRevision':                               'int32',\n",
    "        'Census_OSEdition':                                     'category',\n",
    "        'Census_OSSkuName':                                     'category',\n",
    "        'Census_OSInstallTypeName':                             'category',\n",
    "        'Census_OSInstallLanguageIdentifier':                   'float32',\n",
    "        'Census_OSUILocaleIdentifier':                          'int16',\n",
    "        'Census_OSWUAutoUpdateOptionsName':                     'category',\n",
    "        'Census_IsPortableOperatingSystem':                     'int8',\n",
    "        'Census_GenuineStateName':                              'category',\n",
    "        'Census_ActivationChannel':                             'category',\n",
    "        'Census_IsFlightingInternal':                           'float32',\n",
    "        'Census_IsFlightsDisabled':                             'float32',\n",
    "        'Census_FlightRing':                                    'category',\n",
    "        'Census_ThresholdOptIn':                                'float32',\n",
    "        'Census_FirmwareManufacturerIdentifier':                'float32',\n",
    "        'Census_FirmwareVersionIdentifier':                     'float32',\n",
    "        'Census_IsSecureBootEnabled':                           'int8',\n",
    "        'Census_IsWIMBootEnabled':                              'float32',\n",
    "        'Census_IsVirtualDevice':                               'float32',\n",
    "        'Census_IsTouchEnabled':                                'int8',\n",
    "        'Census_IsPenCapable':                                  'int8',\n",
    "        'Census_IsAlwaysOnAlwaysConnectedCapable':              'float32',\n",
    "        'Wdft_IsGamer':                                         'float32',\n",
    "        'Wdft_RegionIdentifier':                                'float32',\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = '/Users/rishis/Desktop/School/ML/Project/test.csv'\n",
    "test = pd.read_csv(test_dir,dtype=dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nj/j6fj3fg56nz_5zy5vj2yfjmw0000gn/T/ipykernel_39918/1951247845.py:1: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  test['SmartScreen'].replace({ '0':'off', '00000000':'off','BLOCK':'Block', 'off':'Off',\n",
      "/var/folders/nj/j6fj3fg56nz_5zy5vj2yfjmw0000gn/T/ipykernel_39918/1951247845.py:1: FutureWarning: The behavior of Series.replace (and DataFrame.replace) with CategoricalDtype is deprecated. In a future version, replace will only be used for cases that preserve the categories. To change the categories, use ser.cat.rename_categories instead.\n",
      "  test['SmartScreen'].replace({ '0':'off', '00000000':'off','BLOCK':'Block', 'off':'Off',\n"
     ]
    }
   ],
   "source": [
    "test['SmartScreen'].replace({ '0':'off', '00000000':'off','BLOCK':'Block', 'off':'Off', \n",
    "                              'on':'On', 'requireadmin' : 'RequireAdmin', 'Enabled' : 'on', \n",
    "                              'OFF' : 'Off', 'Promt' : 'Prompt', 'prompt' : 'Prompt', 'on' : 'On', \n",
    "                              'off' : 'Off', 'warn' : 'RequireAdmin', 'requireAdmin' : 'RequireAdmin', '&#x03;' : '&#x01;'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import category_encoders as ce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['MachineIdentifier']\n",
    "columns_to_freq_encode = ['AppVersion','AvSigVersion','Census_OSVersion','EngineVersion','OsBuildLab']\n",
    "columns_for_LE = ['ProductName','RtpStateBitfield','Platform','Processor','OsVer','OsBuild','OsSuite',\n",
    "                   'OsPlatformSubRelease','OsBuildLab','SkuEdition','PuaMode','SmartScreen','Census_MDC2FormFactor',\n",
    "                  'Census_DeviceFamily','Census_ProcessorClass','Census_PrimaryDiskTypeName','Census_ChassisTypeName',\n",
    "                  'Census_PowerPlatformRoleName','Census_InternalBatteryType','Census_OSArchitecture',\n",
    "                  'Census_OSBranch','Census_OSEdition','Census_OSSkuName','Census_OSInstallTypeName',\n",
    "                  'Census_OSWUAutoUpdateOptionsName','Census_GenuineStateName','Census_ActivationChannel',\n",
    "                  'Census_FlightRing']\n",
    "columns_with_strings = ['ProductName','Platform','Processor','OsPlatformSubRelease','OsBuildLab','SkuEdition',\n",
    "                        'PuaMode','SmartScreen','Census_MDC2FormFactor','Census_DeviceFamily','Census_PrimaryDiskTypeName',\n",
    "                        'Census_ChassisTypeName','Census_PowerPlatformRoleName','Census_InternalBatteryType',\n",
    "                        'Census_OSArchitecture','Census_OSBranch','Census_OSEdition','Census_OSSkuName','Census_OSInstallTypeName',\n",
    "                        'Census_OSWUAutoUpdateOptionsName','Census_GenuineStateName','Census_ActivationChannel',\n",
    "                        'Census_FlightRing']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "identiers = test['MachineIdentifier']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unwanted columns\n",
    "for col in columns_to_drop:\n",
    "    test.drop(columns=[col], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert string columns to lowercase\n",
    "for col in columns_with_strings:\n",
    "    test[col] = test[col].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rishis/Desktop/School/ML/Project/.conda/lib/python3.11/site-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator StandardScaler from version 1.6.0 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/Users/rishis/Desktop/School/ML/Project/.conda/lib/python3.11/site-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator LabelEncoder from version 1.6.0 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load the saved encoders\n",
    "scaler_dir = '/Users/rishis/Desktop/School/ML/Project/dnn-refact/ML-project/Encoder pickle Files/Custom Encodings/scaler.pkl'\n",
    "freq_encoder_dir = '/Users/rishis/Desktop/School/ML/Project/dnn-refact/ML-project/Encoder pickle Files/Custom Encodings/freq_encoder.pkl'\n",
    "label_encoders_dir = '/Users/rishis/Desktop/School/ML/Project/dnn-refact/ML-project/Encoder pickle Files/Custom Encodings/label_encoders.pkl'\n",
    "\n",
    "# Load the saved objects\n",
    "scaler = pickle.load(open(scaler_dir, 'rb'))\n",
    "freq_encoder = pickle.load(open(freq_encoder_dir, 'rb'))\n",
    "label_encoders = pickle.load(open(label_encoders_dir, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[columns_to_freq_encode] = freq_encoder.transform(test[columns_to_freq_encode])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace NaNs in other columns\n",
    "for col in test.columns:\n",
    "    if test[col].dtype == 'object':\n",
    "        test[col] = test[col].fillna('NA')\n",
    "    elif test[col].dtype == 'category':\n",
    "        test[col] = test[col].cat.add_categories('NA').fillna('NA')\n",
    "    else:\n",
    "        test[col] = test[col].fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nj/j6fj3fg56nz_5zy5vj2yfjmw0000gn/T/ipykernel_39918/286798803.py:6: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(test[col]):  # If categorical, add '-1' category first\n",
      "/var/folders/nj/j6fj3fg56nz_5zy5vj2yfjmw0000gn/T/ipykernel_39918/286798803.py:6: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(test[col]):  # If categorical, add '-1' category first\n",
      "/var/folders/nj/j6fj3fg56nz_5zy5vj2yfjmw0000gn/T/ipykernel_39918/286798803.py:6: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(test[col]):  # If categorical, add '-1' category first\n",
      "/var/folders/nj/j6fj3fg56nz_5zy5vj2yfjmw0000gn/T/ipykernel_39918/286798803.py:6: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(test[col]):  # If categorical, add '-1' category first\n",
      "/var/folders/nj/j6fj3fg56nz_5zy5vj2yfjmw0000gn/T/ipykernel_39918/286798803.py:6: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(test[col]):  # If categorical, add '-1' category first\n",
      "/var/folders/nj/j6fj3fg56nz_5zy5vj2yfjmw0000gn/T/ipykernel_39918/286798803.py:6: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(test[col]):  # If categorical, add '-1' category first\n",
      "/var/folders/nj/j6fj3fg56nz_5zy5vj2yfjmw0000gn/T/ipykernel_39918/286798803.py:6: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(test[col]):  # If categorical, add '-1' category first\n",
      "/var/folders/nj/j6fj3fg56nz_5zy5vj2yfjmw0000gn/T/ipykernel_39918/286798803.py:6: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(test[col]):  # If categorical, add '-1' category first\n",
      "/var/folders/nj/j6fj3fg56nz_5zy5vj2yfjmw0000gn/T/ipykernel_39918/286798803.py:6: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(test[col]):  # If categorical, add '-1' category first\n",
      "/var/folders/nj/j6fj3fg56nz_5zy5vj2yfjmw0000gn/T/ipykernel_39918/286798803.py:6: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(test[col]):  # If categorical, add '-1' category first\n",
      "/var/folders/nj/j6fj3fg56nz_5zy5vj2yfjmw0000gn/T/ipykernel_39918/286798803.py:6: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(test[col]):  # If categorical, add '-1' category first\n",
      "/var/folders/nj/j6fj3fg56nz_5zy5vj2yfjmw0000gn/T/ipykernel_39918/286798803.py:6: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(test[col]):  # If categorical, add '-1' category first\n",
      "/var/folders/nj/j6fj3fg56nz_5zy5vj2yfjmw0000gn/T/ipykernel_39918/286798803.py:6: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(test[col]):  # If categorical, add '-1' category first\n",
      "/var/folders/nj/j6fj3fg56nz_5zy5vj2yfjmw0000gn/T/ipykernel_39918/286798803.py:6: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(test[col]):  # If categorical, add '-1' category first\n",
      "/var/folders/nj/j6fj3fg56nz_5zy5vj2yfjmw0000gn/T/ipykernel_39918/286798803.py:6: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(test[col]):  # If categorical, add '-1' category first\n",
      "/var/folders/nj/j6fj3fg56nz_5zy5vj2yfjmw0000gn/T/ipykernel_39918/286798803.py:6: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(test[col]):  # If categorical, add '-1' category first\n",
      "/var/folders/nj/j6fj3fg56nz_5zy5vj2yfjmw0000gn/T/ipykernel_39918/286798803.py:6: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(test[col]):  # If categorical, add '-1' category first\n",
      "/var/folders/nj/j6fj3fg56nz_5zy5vj2yfjmw0000gn/T/ipykernel_39918/286798803.py:6: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(test[col]):  # If categorical, add '-1' category first\n",
      "/var/folders/nj/j6fj3fg56nz_5zy5vj2yfjmw0000gn/T/ipykernel_39918/286798803.py:6: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(test[col]):  # If categorical, add '-1' category first\n",
      "/var/folders/nj/j6fj3fg56nz_5zy5vj2yfjmw0000gn/T/ipykernel_39918/286798803.py:6: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(test[col]):  # If categorical, add '-1' category first\n",
      "/var/folders/nj/j6fj3fg56nz_5zy5vj2yfjmw0000gn/T/ipykernel_39918/286798803.py:6: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(test[col]):  # If categorical, add '-1' category first\n",
      "/var/folders/nj/j6fj3fg56nz_5zy5vj2yfjmw0000gn/T/ipykernel_39918/286798803.py:6: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(test[col]):  # If categorical, add '-1' category first\n",
      "/var/folders/nj/j6fj3fg56nz_5zy5vj2yfjmw0000gn/T/ipykernel_39918/286798803.py:6: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(test[col]):  # If categorical, add '-1' category first\n",
      "/var/folders/nj/j6fj3fg56nz_5zy5vj2yfjmw0000gn/T/ipykernel_39918/286798803.py:6: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(test[col]):  # If categorical, add '-1' category first\n",
      "/var/folders/nj/j6fj3fg56nz_5zy5vj2yfjmw0000gn/T/ipykernel_39918/286798803.py:6: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(test[col]):  # If categorical, add '-1' category first\n",
      "/var/folders/nj/j6fj3fg56nz_5zy5vj2yfjmw0000gn/T/ipykernel_39918/286798803.py:6: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(test[col]):  # If categorical, add '-1' category first\n",
      "/var/folders/nj/j6fj3fg56nz_5zy5vj2yfjmw0000gn/T/ipykernel_39918/286798803.py:6: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(test[col]):  # If categorical, add '-1' category first\n",
      "/var/folders/nj/j6fj3fg56nz_5zy5vj2yfjmw0000gn/T/ipykernel_39918/286798803.py:6: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(test[col]):  # If categorical, add '-1' category first\n"
     ]
    }
   ],
   "source": [
    "for col in columns_for_LE:\n",
    "    if col in test.columns and col in label_encoders:\n",
    "        le = label_encoders[col]\n",
    "        le_dict = {cls: idx for idx, cls in enumerate(le.classes_)}\n",
    "        \n",
    "        if pd.api.types.is_categorical_dtype(test[col]):  # If categorical, add '-1' category first\n",
    "            test[col] = test[col].cat.add_categories([-1]).map(le_dict).fillna(-1).astype('int8')\n",
    "        else:\n",
    "            test[col] = test[col].map(le_dict).fillna(-1).astype('int8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert float64 and object columns to float32\n",
    "for col in test.columns:\n",
    "    if test[col].dtype == 'float64':\n",
    "        test[col] = test[col].astype('float32')\n",
    "    elif test[col].dtype == 'object':\n",
    "        test[col] = test[col].astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/rishis/Desktop/School/ML/Project/dnn-refact/ML-project/')\n",
    "import helper_functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 1138.40 Mb (25.5% reduction)\n"
     ]
    }
   ],
   "source": [
    "X = helper_functions.reduce_mem_usage(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgboost_dir=r'C:\\Users\\jithi\\OneDrive\\Desktop\\ML project\\xgb_model.json'\n",
    "# xgb_loaded = XGBClassifier(enable_categorical=True)\n",
    "# xgb_loaded.load_model(xgboost_dir)\n",
    "# predictions = xgb_loaded.predict(X)\n",
    "# probs = xgb_loaded.predict_proba(X_scaled)\n",
    "# probs = probs[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test loader on X\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "tensor_X = torch.from_numpy(X.values.astype('float32'))\n",
    "test_dataset = TensorDataset(tensor_X)\n",
    "batch_size = 2048\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Two_Hidden(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(Two_Hidden, self).__init__()\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 256), \n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),                            \n",
    "            \n",
    "            nn.Linear(256, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "\n",
    "            nn.Linear(128, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "\n",
    "            nn.Linear(64, 1) \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define complex model\n",
    "class Three_Hidden(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(Three_Hidden, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_dim, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.Dropout(0.3),\n",
    "\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Dropout(0.3),\n",
    "\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.Dropout(0.4),\n",
    "\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.Dropout(0.4),\n",
    "\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Four_Hidden(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(Four_Hidden, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_dim, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.Dropout(0.3),\n",
    "\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.Dropout(0.3),\n",
    "\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Dropout(0.3),\n",
    "            \n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.Dropout(0.4),\n",
    "\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.Dropout(0.4),\n",
    "\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3835/3835 [00:21<00:00, 175.39it/s]\n"
     ]
    }
   ],
   "source": [
    "input_dim = X.shape[1]\n",
    "model = Two_Hidden(input_dim)\n",
    "\n",
    "# Use AdamW optimizer\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, min_lr=1e-6)\n",
    "\n",
    "state_dict = torch.load('/Users/rishis/Desktop/School/ML/Project/dnn-refact/ML-project/Saved Models/simplenn_custom_encodings.pth', map_location=torch.device('mps'))\n",
    "model.load_state_dict(state_dict)\n",
    "\n",
    "#predict on test set\n",
    "model.eval()\n",
    "predictions = []\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader):\n",
    "        # batch could be just inputs or (inputs, labels)\n",
    "        inputs = batch[0] if isinstance(batch, (list, tuple)) else batch\n",
    "        \n",
    "        # Move inputs to GPU if needed\n",
    "        inputs = inputs.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # Move outputs back to CPU, detach from graph\n",
    "        outputs_cpu = outputs.detach().cpu().numpy()\n",
    "        \n",
    "        # Either store them in memory (if it’s not too large)...\n",
    "        predictions.append(outputs_cpu)\n",
    "        # ... or write to disk incrementally\n",
    "\n",
    "# If storing in memory, then concatenate at the end\n",
    "predictions = np.concatenate(predictions, axis=0)\n",
    "probs = predictions.flatten()\n",
    "\n",
    "submission = pd.DataFrame(\n",
    "    {'MachineIdentifier': identiers, 'HasDetections': probs})\n",
    "submission.to_csv('hl_2_initial.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3835/3835 [00:21<00:00, 179.05it/s]\n"
     ]
    }
   ],
   "source": [
    "input_dim = X.shape[1]\n",
    "model = Three_Hidden(input_dim)\n",
    "\n",
    "# Use AdamW optimizer\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, min_lr=1e-6)\n",
    "\n",
    "state_dict = torch.load('/Users/rishis/Desktop/School/ML/Project/dnn-refact/ML-project/pytorch-models/deepernn_custom_encodings.pth', map_location=torch.device('mps'))\n",
    "model.load_state_dict(state_dict)\n",
    "\n",
    "#predict on test set\n",
    "model.eval()\n",
    "predictions = []\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader):\n",
    "        # batch could be just inputs or (inputs, labels)\n",
    "        inputs = batch[0] if isinstance(batch, (list, tuple)) else batch\n",
    "        \n",
    "        # Move inputs to GPU if needed\n",
    "        inputs = inputs.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # Move outputs back to CPU, detach from graph\n",
    "        outputs_cpu = outputs.detach().cpu().numpy()\n",
    "        \n",
    "        # Either store them in memory (if it’s not too large)...\n",
    "        predictions.append(outputs_cpu)\n",
    "        # ... or write to disk incrementally\n",
    "\n",
    "# If storing in memory, then concatenate at the end\n",
    "predictions = np.concatenate(predictions, axis=0)\n",
    "probs = predictions.flatten()\n",
    "\n",
    "submission = pd.DataFrame(\n",
    "    {'MachineIdentifier': identiers, 'HasDetections': probs})\n",
    "submission.to_csv('hl_3_initial.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_features = [\n",
    "    \"Census_OSBuildNumber\",\n",
    "    \"OsBuild\",\n",
    "    \"Census_InternalBatteryType\",\n",
    "    \"Census_InternalBatteryNumberOfCharges\",\n",
    "    \"Census_IsWIMBootEnabled\",\n",
    "    \"Census_ThresholdOptIn\",\n",
    "    \"OsVer\",\n",
    "    \"Platform\",\n",
    "    \"Census_ChassisTypeName\",\n",
    "    \"Census_MDC2FormFactor\",\n",
    "    \"Census_InternalPrimaryDisplayResolutionVertical\",\n",
    "    \"Census_OSSkuName\",\n",
    "    \"AppVersion\",\n",
    "    \"Census_OSEdition\",\n",
    "    \"OsSuite\",\n",
    "    \"Census_InternalPrimaryDisplayResolutionHorizontal\",\n",
    "    \"Census_InternalPrimaryDiagonalDisplaySizeInInches\",\n",
    "    \"SkuEdition\",\n",
    "    \"OsBuildLab\",\n",
    "    \"Census_OSVersion\",\n",
    "    \"SmartScreen\",\n",
    "    \"Census_TotalPhysicalRAM\",\n",
    "    \"Census_OSBranch\",\n",
    "    \"Census_PowerPlatformRoleName\",\n",
    "    \"ProductName\",\n",
    "    \"Census_IsFlightingInternal\",\n",
    "    \"HasTpm\",\n",
    "    \"Census_ProcessorCoreCount\",\n",
    "    \"Census_OSBuildRevision\",\n",
    "    \"OsPlatformSubRelease\",\n",
    "    \"Census_IsFlightsDisabled\",\n",
    "    \"Census_FirmwareManufacturerIdentifier\",\n",
    "    \"Census_IsSecureBootEnabled\",\n",
    "    \"Firewall\",\n",
    "    \"Census_FlightRing\",\n",
    "    \"Census_PrimaryDiskTypeName\",\n",
    "    \"EngineVersion\",\n",
    "    \"IeVerIdentifier\",\n",
    "    \"Census_ProcessorModelIdentifier\",\n",
    "    \"Census_FirmwareVersionIdentifier\",\n",
    "    \"Census_ProcessorClass\",\n",
    "    \"AVProductsInstalled\",\n",
    "    \"Wdft_IsGamer\",\n",
    "    \"Census_OEMNameIdentifier\",\n",
    "    \"IsProtected\",\n",
    "    \"Processor\",\n",
    "    \"Census_OSArchitecture\",\n",
    "    \"AVProductStatesIdentifier\",\n",
    "    \"SMode\",\n",
    "    \"Census_OEMModelIdentifier\",\n",
    "    \"Wdft_RegionIdentifier\",\n",
    "    \"Census_OSInstallLanguageIdentifier\",\n",
    "    \"DefaultBrowsersIdentifier\",\n",
    "    \"AVProductsEnabled\",\n",
    "    \"Census_GenuineStateName\",\n",
    "    \"AvSigVersion\",\n",
    "    \"Census_OSWUAutoUpdateOptionsName\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test loader on X\n",
    "tensor_X = torch.from_numpy(X[pca_features].values.astype('float32'))\n",
    "test_dataset = TensorDataset(tensor_X)\n",
    "batch_size = 2048\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3835/3835 [00:19<00:00, 200.00it/s]\n"
     ]
    }
   ],
   "source": [
    "input_dim = X[pca_features].shape[1]\n",
    "model = Two_Hidden(input_dim)\n",
    "\n",
    "# Use AdamW optimizer\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, min_lr=1e-6)\n",
    "\n",
    "state_dict = torch.load('/Users/rishis/Desktop/School/ML/Project/dnn-refact/ML-project/Saved Models/simplenn_custom_encodings_pca.pth', map_location=torch.device('mps'))\n",
    "model.load_state_dict(state_dict)\n",
    "\n",
    "#predict on test set\n",
    "model.eval()\n",
    "predictions = []\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader):\n",
    "        # batch could be just inputs or (inputs, labels)\n",
    "        inputs = batch[0] if isinstance(batch, (list, tuple)) else batch\n",
    "        \n",
    "        # Move inputs to GPU if needed\n",
    "        inputs = inputs.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # Move outputs back to CPU, detach from graph\n",
    "        outputs_cpu = outputs.detach().cpu().numpy()\n",
    "        \n",
    "        # Either store them in memory (if it’s not too large)...\n",
    "        predictions.append(outputs_cpu)\n",
    "        # ... or write to disk incrementally\n",
    "\n",
    "# If storing in memory, then concatenate at the end\n",
    "predictions = np.concatenate(predictions, axis=0)\n",
    "probs = predictions.flatten()\n",
    "\n",
    "submission = pd.DataFrame(\n",
    "    {'MachineIdentifier': identiers, 'HasDetections': probs})\n",
    "submission.to_csv('hl_2_initial_pca.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3835/3835 [00:21<00:00, 181.92it/s]\n"
     ]
    }
   ],
   "source": [
    "input_dim = X[pca_features].shape[1]\n",
    "model = Three_Hidden(input_dim)\n",
    "\n",
    "# Use AdamW optimizer\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, min_lr=1e-6)\n",
    "\n",
    "state_dict = torch.load('/Users/rishis/Desktop/School/ML/Project/dnn-refact/ML-project/pytorch-models/deepernn_custom_encodings_pca.pth', map_location=torch.device('mps'))\n",
    "model.load_state_dict(state_dict)\n",
    "\n",
    "#predict on test set\n",
    "model.eval()\n",
    "predictions = []\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader):\n",
    "        # batch could be just inputs or (inputs, labels)\n",
    "        inputs = batch[0] if isinstance(batch, (list, tuple)) else batch\n",
    "        \n",
    "        # Move inputs to GPU if needed\n",
    "        inputs = inputs.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # Move outputs back to CPU, detach from graph\n",
    "        outputs_cpu = outputs.detach().cpu().numpy()\n",
    "        \n",
    "        # Either store them in memory (if it’s not too large)...\n",
    "        predictions.append(outputs_cpu)\n",
    "        # ... or write to disk incrementally\n",
    "\n",
    "# If storing in memory, then concatenate at the end\n",
    "predictions = np.concatenate(predictions, axis=0)\n",
    "probs = predictions.flatten()\n",
    "\n",
    "submission = pd.DataFrame(\n",
    "    {'MachineIdentifier': identiers, 'HasDetections': probs})\n",
    "submission.to_csv('hl_3_initial_pca.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_features = [\n",
    "    'Census_OSEdition', \n",
    "    'Census_OSSkuName', \n",
    "    'AVProductsInstalled', \n",
    "    'EngineVersion', \n",
    "    'SmartScreen',\n",
    "    'AVProductStatesIdentifier', \n",
    "    'Census_ThresholdOptIn', \n",
    "    'IsProtected', \n",
    "    'Census_OSInstallTypeName',\n",
    "    'Census_IsVirtualDevice', \n",
    "    'Census_InternalPrimaryDisplayResolutionVertical', \n",
    "    'OsSuite',\n",
    "    'Census_InternalPrimaryDisplayResolutionHorizontal', \n",
    "    'Processor',\n",
    "    'Census_IsAlwaysOnAlwaysConnectedCapable', \n",
    "    'Wdft_IsGamer', \n",
    "    'Census_OSVersion',\n",
    "    'Census_OSUILocaleIdentifier', \n",
    "    'Census_InternalBatteryNumberOfCharges', \n",
    "    'Census_IsTouchEnabled',\n",
    "    'Census_OSBuildNumber', \n",
    "    'HasTpm', \n",
    "    'SMode', \n",
    "    'Census_MDC2FormFactor',\n",
    "    'Census_OSInstallLanguageIdentifier', \n",
    "    'Census_DeviceFamily', \n",
    "    'Census_HasOpticalDiskDrive',\n",
    "    'Census_TotalPhysicalRAM', \n",
    "    'Census_InternalBatteryType', \n",
    "    'Census_PrimaryDiskTypeName',\n",
    "    'LocaleEnglishNameIdentifier', \n",
    "    'ProductName', \n",
    "    'Census_ProcessorCoreCount', \n",
    "    'Wdft_RegionIdentifier',\n",
    "    'DefaultBrowsersIdentifier', \n",
    "    'Census_IsSecureBootEnabled', \n",
    "    'Census_GenuineStateName',\n",
    "    'RtpStateBitfield', \n",
    "    'OsBuild', \n",
    "    'SkuEdition', \n",
    "    'OsPlatformSubRelease', \n",
    "    'Census_IsFlightingInternal',\n",
    "    'Census_FlightRing', \n",
    "    'OsVer', \n",
    "    'Census_ProcessorModelIdentifier', \n",
    "    'Census_ActivationChannel',\n",
    "    'IeVerIdentifier', \n",
    "    'Census_OSBuildRevision', \n",
    "    'AvSigVersion', \n",
    "    'AppVersion',\n",
    "    'Census_OSWUAutoUpdateOptionsName', \n",
    "    'Census_OEMNameIdentifier', \n",
    "    'Census_OSArchitecture',\n",
    "    'Census_ChassisTypeName', \n",
    "    'Census_PowerPlatformRoleName', \n",
    "    'PuaMode', \n",
    "    'Census_OEMModelIdentifier',\n",
    "    'Census_ProcessorClass', \n",
    "    'Census_ProcessorManufacturerIdentifier', \n",
    "    'Census_IsFlightsDisabled',\n",
    "    'Census_OSBranch', \n",
    "    'AVProductsEnabled', \n",
    "    'Census_SystemVolumeTotalCapacity', \n",
    "    'CityIdentifier',\n",
    "    'Census_IsPortableOperatingSystem', \n",
    "    'IsSxsPassiveMode', \n",
    "    'Census_FirmwareManufacturerIdentifier',\n",
    "    'OrganizationIdentifier', \n",
    "    'Census_InternalPrimaryDiagonalDisplaySizeInInches', \n",
    "    'AutoSampleOptIn',\n",
    "    'OsBuildLab', \n",
    "    'Census_FirmwareVersionIdentifier', \n",
    "    'CountryIdentifier', \n",
    "    'UacLuaenable', \n",
    "    'IsBeta',\n",
    "    'Firewall', \n",
    "    'Census_IsPenCapable', \n",
    "    'Census_PrimaryDiskTotalCapacity', \n",
    "    'Platform',\n",
    "    'Census_IsWIMBootEnabled', \n",
    "    'GeoNameIdentifier'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test loader on X\n",
    "tensor_X = torch.from_numpy(X[lda_features].values.astype('float32'))\n",
    "test_dataset = TensorDataset(tensor_X)\n",
    "batch_size = 2048\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3835/3835 [00:20<00:00, 188.76it/s]\n"
     ]
    }
   ],
   "source": [
    "input_dim = X[lda_features].shape[1]\n",
    "model = Two_Hidden(input_dim)\n",
    "\n",
    "# Use AdamW optimizer\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, min_lr=1e-6)\n",
    "\n",
    "state_dict = torch.load('/Users/rishis/Desktop/School/ML/Project/dnn-refact/ML-project/Saved Models/simplenn_custom_encodings_lda.pth', map_location=torch.device('mps'))\n",
    "model.load_state_dict(state_dict)\n",
    "\n",
    "#predict on test set\n",
    "model.eval()\n",
    "predictions = []\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader):\n",
    "        # batch could be just inputs or (inputs, labels)\n",
    "        inputs = batch[0] if isinstance(batch, (list, tuple)) else batch\n",
    "        \n",
    "        # Move inputs to GPU if needed\n",
    "        inputs = inputs.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # Move outputs back to CPU, detach from graph\n",
    "        outputs_cpu = outputs.detach().cpu().numpy()\n",
    "        \n",
    "        # Either store them in memory (if it’s not too large)...\n",
    "        predictions.append(outputs_cpu)\n",
    "        # ... or write to disk incrementally\n",
    "\n",
    "# If storing in memory, then concatenate at the end\n",
    "predictions = np.concatenate(predictions, axis=0)\n",
    "probs = predictions.flatten()\n",
    "\n",
    "submission = pd.DataFrame(\n",
    "    {'MachineIdentifier': identiers, 'HasDetections': probs})\n",
    "submission.to_csv('hl_2_initial_lda.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3835/3835 [00:23<00:00, 165.00it/s]\n"
     ]
    }
   ],
   "source": [
    "input_dim = X[lda_features].shape[1]\n",
    "model = Three_Hidden(input_dim)\n",
    "\n",
    "# Use AdamW optimizer\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, min_lr=1e-6)\n",
    "\n",
    "state_dict = torch.load('/Users/rishis/Desktop/School/ML/Project/dnn-refact/ML-project/pytorch-models/deepernn_custom_encodings_lda.pth', map_location=torch.device('mps'))\n",
    "model.load_state_dict(state_dict)\n",
    "\n",
    "#predict on test set\n",
    "model.eval()\n",
    "predictions = []\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader):\n",
    "        # batch could be just inputs or (inputs, labels)\n",
    "        inputs = batch[0] if isinstance(batch, (list, tuple)) else batch\n",
    "        \n",
    "        # Move inputs to GPU if needed\n",
    "        inputs = inputs.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # Move outputs back to CPU, detach from graph\n",
    "        outputs_cpu = outputs.detach().cpu().numpy()\n",
    "        \n",
    "        # Either store them in memory (if it’s not too large)...\n",
    "        predictions.append(outputs_cpu)\n",
    "        # ... or write to disk incrementally\n",
    "\n",
    "# If storing in memory, then concatenate at the end\n",
    "predictions = np.concatenate(predictions, axis=0)\n",
    "probs = predictions.flatten()\n",
    "\n",
    "submission = pd.DataFrame(\n",
    "    {'MachineIdentifier': identiers, 'HasDetections': probs})\n",
    "submission.to_csv('hl_3_initial_lda.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
